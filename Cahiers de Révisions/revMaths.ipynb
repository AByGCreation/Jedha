{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T17:52:29.437924Z",
     "start_time": "2024-11-11T17:52:23.071442Z"
    }
   },
   "outputs": [],
   "source": [
    "#import des libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "h1 {\n",
    "  border: 1.5px solid #333;\n",
    "  padding: 8px 12px;\n",
    "  background-image: linear-gradient(180deg, #fff, rgb(160, 147, 147));\n",
    "  position: static;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "# Structure de Révision pour les Mathématiques @ Jedha\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Algèbre\n",
    "\n",
    "### 1.1. Équations et Inéquations\n",
    "- Résolution d'équations linéaires\n",
    "- Résolution d'équations quadratiques\n",
    "- Systèmes d'équations\n",
    "- Inéquations et systèmes d'inéquations\n",
    "\n",
    "### 1.2. Fonctions\n",
    "- Fonctions linéaires\n",
    "- Fonctions quadratiques\n",
    "- Fonctions exponentielles et logarithmiques\n",
    "- Fonctions trigonométriques\n",
    "\n",
    "### 1.3. Matrices\n",
    "#### 1.3.1 Diagonalisation de matrice\n",
    "0. À quoi ça sert ? \n",
    "\n",
    "La diagonalisation d’une matrice est un outil puissant en algèbre linéaire qui simplifie les calculs liés aux matrices et aux systèmes linéaires. \n",
    "Voici à quoi elle sert principalement :\n",
    "\n",
    "1. Simplification des calculs de puissances de matrices\n",
    "Quand une matrice est diagonalisée, elle peut être décomposée sous la forme $A = PDP^{-1} $, où D est une matrice diagonale et P est une matrice de passage. \n",
    "\n",
    "Cela simplifie considérablement le calcul des puissances de la matrice A, car : $A^n = P D^n P^{-1}$\n",
    "Calculer $D^n$ est beaucoup plus simple, puisque D est diagonale et chaque élément diagonal est juste élevé à la puissance n.\n",
    "\n",
    "2. Compréhension et analyse des systèmes dynamiques\n",
    "    La diagonalisation aide à comprendre le comportement à long terme des systèmes dynamiques linéaires. \n",
    "    Par exemple, dans l’étude des systèmes différentielles ou des chaînes de Markov, connaître la diagonalisation permet de prévoir comment un système évolue au fil du temps.\n",
    "\n",
    "3. Applications dans la résolution d’équations différentielles\n",
    "\n",
    "    La diagonalisation est utile pour résoudre des systèmes d’équations différentielles linéaires. \n",
    "    En diagonalissant la matrice associée, on peut décomposer le système en équations plus simples à résoudre.\n",
    "\n",
    "4. Transformation linéaire simplifiée\n",
    "\n",
    "    Dans le contexte de la géométrie, diagonaliser une matrice permet de comprendre et de simplifier la transformation linéaire qu’elle représente, car la matrice diagonale indique directement les valeurs propres qui définissent l’étirement ou la compression dans les directions propres.\n",
    "\n",
    "5. Décomposition spectrale\n",
    "\n",
    "    La diagonalisation est liée à la décomposition spectrale, qui permet de décomposer une matrice en une somme de matrices pondérées par leurs valeurs propres. \n",
    "    Cela a des applications dans la mécanique quantique, la vibration des structures, l’analyse des graphes, et la compression de données (comme l’analyse en composantes principales).\n",
    "    \n",
    "##### Etapes pour diagonaliser une matrice :\n",
    "\n",
    "0. Pour toute matrice A\n",
    "1. Calcul des valeurs propres (eighenValues)\n",
    "2. Calcul des vecteurs propres (eighenVectors ou matrice P), c'est la construction de la matrice de passage P tel que → Chaque colonne de P est un vecteur propre de A \n",
    "3. Verifier l'independance lineaire des vecteurs propres, revient à verifier que la matrice P formé par ces vecteurs est inversible. La mtrice est inversible si son detertmiannt est non nul (det_P ≠ 0) \n",
    "4. Construction de la matrice diagonale D tel que → La matrice D a pour valeur diagonle les valeurs propres de A placées dans le meme ordre que les vecteurs propres de P\n",
    "5. Calcul de l'inverse de P → $P^{-1}$\n",
    "6. Verifier l'equation  $A = PDP^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T17:52:29.493052Z",
     "start_time": "2024-11-11T17:52:29.440868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______Diagonalisation d'une matrice 3x3______________\n",
      "0 : Matrice : \n",
      "[[2 1 1]\n",
      " [1 3 1]\n",
      " [1 1 4]]\n",
      "______________________________________________________\n",
      "1 : Valeurs propres : \n",
      "[5.21431974 1.32486913 2.46081113]\n",
      "______________________________________________________\n",
      "2 : Vecteurs propres : \n",
      "[[ 0.39711255  0.88765034 -0.23319198]\n",
      " [ 0.52065737 -0.42713229 -0.73923874]\n",
      " [ 0.75578934 -0.17214786  0.63178128]]\n",
      "______________________________________________________\n",
      "3 : Verification de l'independance des vecteurs propres : \n",
      "Les vecteurs propres sont independants\n",
      "______________________________________________________\n",
      "4 : Construction de la matrice de passage P : \n",
      "[[ 0.39711255  0.52065737  0.75578934]\n",
      " [ 0.88765034 -0.42713229 -0.17214786]\n",
      " [-0.23319198 -0.73923874  0.63178128]]\n",
      "______________________________________________________\n",
      "5 : Construction de la matrice diagonale : \n",
      "[[5.21431974 0.         0.        ]\n",
      " [0.         1.32486913 0.        ]\n",
      " [0.         0.         2.46081113]]\n",
      "______________________________________________________\n",
      "6 : Inverse de la matrice des vecteurs propres : \n",
      "[[ 0.39711255  0.52065737  0.75578934]\n",
      " [ 0.88765034 -0.42713229 -0.17214786]\n",
      " [-0.23319198 -0.73923874  0.63178128]]\n",
      "______________________________________________________\n",
      "7 : Verification de la diagonalisation de la matrice : \n",
      "[[2. 1. 1.]\n",
      " [1. 3. 1.]\n",
      " [1. 1. 4.]]\n",
      "______________________________________________________\n"
     ]
    }
   ],
   "source": [
    "matrix = np.array([[2, 1, 1], \n",
    "                   [1, 3, 1], \n",
    "                   [1, 1, 4]])\n",
    "\n",
    "identityMatrix = np.identity(3) # Matrice identité 3x3\n",
    "\n",
    "print(\"_______Diagonalisation d'une matrice 3x3______________\")\n",
    "print(\"0 : Matrice : \")\n",
    "print(matrix)\n",
    "print(\"______________________________________________________\")\n",
    "# 1 Calcul des valeurs propres\n",
    "print(\"1 : Valeurs propres : \")\n",
    "eigenValues = np.linalg.eigvals(matrix)\n",
    "print(eigenValues)\n",
    "print(\"______________________________________________________\")\n",
    "# 2 Calcul des vecteurs propres\n",
    "print(\"2 : Vecteurs propres : \")\n",
    "eigenVectors = np.linalg.eig(matrix)[1]\n",
    "print(eigenVectors)\n",
    "print(\"______________________________________________________\")\n",
    "\n",
    "#3 verification de l'independance des vecteurs propres\n",
    "print(\"3 : Verification de l'independance des vecteurs propres : \")\n",
    "\n",
    "# on calcule le determinant de la matrice vecteurs propres\n",
    "det_P = np.linalg.det(eigenVectors)\n",
    "\n",
    "if det_P != 0:\n",
    "    print(\"Les vecteurs propres sont independants\")\n",
    "else:\n",
    "    print(\"Les vecteurs propres ne sont pas independants, la matrice n'est pas diagonalisable\")\n",
    "    pass \n",
    "\n",
    "print(\"______________________________________________________\")\n",
    "print(\"4 : Construction de la matrice de passage P : \")\n",
    "# on cherche la matrice inverse de la matrice des vecteurs propres\n",
    "inverse = np.linalg.inv(eigenVectors)\n",
    "print(inverse)\n",
    "print(\"______________________________________________________\")\n",
    "print(\"5 : Construction de la matrice diagonale : \")\n",
    "# on construit la matrice diagonale\n",
    "diagonal = np.diag(eigenValues)\n",
    "print(diagonal)\n",
    "\n",
    "print(\"______________________________________________________\")\n",
    "# on calcule l'inverse de la matrice des vecteurs propres\n",
    "print (\"6 : Inverse de la matrice des vecteurs propres : \")\n",
    "inverse = np.linalg.inv(eigenVectors)\n",
    "print(inverse)\n",
    "print(\"______________________________________________________\")\n",
    "\n",
    "print(\"7 : Verification de la diagonalisation de la matrice : \")\n",
    "# on verifie que la matrice est bien diagonalisable\n",
    "result = eigenVectors @ diagonal @ inverse\n",
    "print(result)\n",
    "print(\"______________________________________________________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T17:52:29.501308Z",
     "start_time": "2024-11-11T17:52:29.495421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagonale avec function python : \n",
      "[2 3 4]\n",
      "______________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Verifications avec les fonctions python\n",
    "print(\"Diagonale avec function python : \")\n",
    "diagonal = np.diag(matrix)\n",
    "print(diagonal)\n",
    "print(\"______________________________________________________\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les deux matrices sont elles égales ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T17:52:29.510908Z",
     "start_time": "2024-11-11T17:52:29.505230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les deux matrices sont elles égales ? \n",
      "diagonale calculée : \n",
      "[[2. 1. 1.]\n",
      " [1. 3. 1.]\n",
      " [1. 1. 4.]]\n",
      "diagonale Python\n",
      "[2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"Les deux matrices sont elles égales ? \")\n",
    "print(\"diagonale calculée : \")\n",
    "print(result)\n",
    "print(\"diagonale Python\")\n",
    "print(diagonal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T17:52:29.515187Z",
     "start_time": "2024-11-11T17:52:29.512888Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Géométrie\n",
    "### 2.1. Géométrie Plane\n",
    "- Propriétés des triangles\n",
    "- Propriétés des quadrilatères\n",
    "- Cercles et angles\n",
    "\n",
    "### 2.2. Géométrie dans l'Espace\n",
    "- Solides et volumes\n",
    "- Coordonnées dans l'espace\n",
    "- Vecteurs et produits scalaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyse\n",
    "### 3.1. Dérivées\n",
    "- Définition\n",
    "- Règles de dérivation\n",
    "- Applications des dérivées\n",
    "\n",
    "### 3.2. Intégrales\n",
    "- Définition et interprétation\n",
    "- Techniques d'intégration\n",
    "- Applications des intégrales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Probabilités et Statistiques\n",
    "\n",
    "### 4.0. Collections, echantillonages et Types de données :\n",
    "\n",
    "\n",
    "Les collections sont utilisées pour connaitre les moyens de collecter les données, ils sont aujourd'hui de quatre types\n",
    "\n",
    "|  Collection  |      Explanation      |  Example |\n",
    "|----------|:-------------|------|\n",
    "| Observational |  Les données observationnelles sont liées à l'etude que l'ont veux mener | Arbres devellopant une maldie dans une forets  |\n",
    "| Experimental |   Les données experimentales sont la suite logique des observations.  Une fois l'observation établie, un comptage peut-être pratiqué, c'est ce que l'on appelle donné expérimentale.  |   Nombre d'arbres infectés |\n",
    "| Transversal | Les Études transversales sont des données qui sont liées au temps. Elles sont écrites et non changeables comme par exemple les données historiques. |  Frise chronologique avec Évènements |\n",
    "| Longitudinal | Les Études longitudinales s'effectuent le long terme et continue de mesurer par les expérimentations, le groupe prealablement étudié. |    Suivi du registre patient |\n",
    "\n",
    "\n",
    "L'echantillonage est le moyen, au sein de notre precedente collection de venir choisir une \"fenetre\" representative de l'ensemble. L'echantillonage est utilisée pour reduire la quantité de données à traiter.\n",
    "C'est egalement un moyen d'extrapolation qui peut etre utlisée dans le cas de sondage qui, par definition, ne peut pas rendre compte de l'entiereté de la population.\n",
    "L'utilisation de l'echantillonage induit une erreur, c'est cette erreur qui doit etre quantifiée !\n",
    "\n",
    "![image](./resources/probability-sampling.png)\n",
    "\n",
    "\n",
    "|  Sampling  |      Explanation      |  Example |\n",
    "|----------|:-------------|------|\n",
    "| Simple Random | This sampling is the simple way to get an unbiased dataset, it uses a random algorithm depending on the robustess of this algorithm|  /  |\n",
    "| Stratified   |  The stratified sampling  | $1600 |\n",
    "| Cluster | The cluster rendering is  |    $1 |\n",
    "| Convenience  |    centered   |   $12 |\n",
    "\n",
    "\n",
    "De manière à \n",
    "\n",
    "\n",
    "|  Data Type  |      Explanation      |  Example |\n",
    "|----------|:-------------|------|\n",
    "| Quantitative (Quantitatif)  |  <ul><li>These datas can be countable it's anything that can be counted.<br> Ces données sont dénombrables et peuvent être comptées.</li><li>They can be Discrete or continue, depending on the nature of datas</li>| age, weight or bolt |\n",
    "| Qualitative  |    They are not countable, these datas can defined or characterize an item/object by a specificity. These datas can be Ordinal or nominal.<br>(  Non dénombrables, ces données peuvent définir ou caractériser un élément/objet par une spécificité. Ces données peuvent être ordinales ou nominales.)   |  gender, color, state of a machine  |\n",
    "| Ordinal | An ordinal data is ordered by size. We are able to ordered and compared them. |  In a survey, the responses can be classified by good or wrong response   |\n",
    "| Nominal | Opposite, nominal data can not be ordered | It's impossible to say if Blue is higher than red |\n",
    "| Discrete | Discrete Datas are without continuity between two value | Number of person, we can count 1 or 2 person, not one and half |\n",
    "| Continuous | Continuois value can be an infinite of solution. There is no one gap in the series of datas |  A Temperature measurement, temperature growth regularly without jump from a value to an another one  |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 4.1. Probabilités\n",
    "- Concepts de base\n",
    "Les probabilités sont un domaine des mathématiques qui permet de quantifier la chance qu’un événement se produise.\n",
    "Voici comment se decline les concepts de base des probabilités :\n",
    "\n",
    "1. Caractere aléatoire\n",
    "    C’est une action dont le résultat est incertain, comme lancer un dé ou tirer une carte.\n",
    "\n",
    "2. Événement\n",
    "    Un événement est un résultat ou un ensemble de résultats d’une expérience. \n",
    "    Par exemple, obtenir un « 6 » lors d’un lancer de dé.\n",
    "\n",
    "3. Espace échantillon\n",
    "    L’ensemble de tous les résultats possibles d’une expérience. \n",
    "   Par exemple, pour un lancer de dé, l’espace échantillon est \\{1, 2, 3, 4, 5, 6\\}.\n",
    "\n",
    "4. Probabilité d’un événement\n",
    "    C’est une valeur entre 0 et 1 qui représente la chance qu’un événement se produise. \n",
    "   La probabilité se calcule ainsi :\n",
    "    $$\n",
    "    P(A) = \\frac{\\text{n }}{\\text{NP }}\n",
    "    $$\n",
    "   Avec     n = nombre de résultats favorables \n",
    "                NP = nombre total de résultats possibles.\n",
    "\n",
    "5. Événements complémentaires\n",
    "    Si A est un événement, son complémentaire $A{\\prime}$  est l’événement où A  ne se produit pas. \n",
    "    Sa probabilité est $P(A{\\prime}) = 1 - P(A)$.\n",
    "\n",
    "6. Union et intersection\n",
    "\t•\tUnion ( $A \\cup B$ ) : Probabilité que A ou B (ou les deux) se produisent.\n",
    "\t•\tIntersection ( $A \\cap B$ ) : Probabilité que A et B se produisent en même temps. \n",
    "\tSi  A  et  B  sont indépendants,  $P(A \\cap B) = P(A) \\cdot P(B) $.\n",
    "\n",
    "7. Indépendance\n",
    "    Deux événements A et B sont indépendants si la réalisation de l’un n’affecte pas la probabilité de l’autre.\n",
    "\n",
    "8. Probabilité conditionnelle\n",
    "    C’est la probabilité qu’un événement A se produise sachant que B s’est déjà produit, notée P(A|B) et calculée par :\n",
    "\n",
    "    $$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "> **Ces concepts permettent de modéliser et de comprendre des situations incertaines et sont à la base des calculs en probabilités.**\n",
    "\n",
    "- Lois de probabilité\n",
    "\n",
    "Faire la liste des lois de probabilités\n",
    "\n",
    "- Variables aléatoires\n",
    "\n",
    "### 4.2. Statistiques descriptive\n",
    "#### 4.2.1 Analyse des données\n",
    "Parcourir nos datasets est essentiel pour comprendre comment s'articule les données. C'est le moment ou nous allons entrevoir les connections qu'il existe entre les differentes variables de nos tables. De cette analyse nous allons egalement estimé la pertienence du remplissage des données; sont-elles suffisantes, y'a t'il des champs vides, les types de données sont-ils bien respectés... \n",
    "\n",
    "Pour cela nous allons procedé à une analyse statistique pour nous aider à meieux comprendre le jeu de données \n",
    "\n",
    "- Etapes clefs de lanalyse des données\n",
    "    1. Calcul de l'intervalle de confiance\n",
    "    2. Calcul des mesures de tendance centrale (moyenne, médiane, mode)\n",
    "    3. Calcul des mesures de dispersion (variance, écart-type, étendue)\n",
    "    4. Analyse des distributions (histogrammes, courbes de densité)\n",
    "    5. Tests statistiques (tests d'hypothèses, tests de normalité)\n",
    "    6. Analyse de corrélation (coefficients de corrélation, matrices de corrélation)\n",
    "\n",
    "\n",
    "#### 4.2.2. Intervalle de confiance\n",
    "\n",
    "L'intervalle de confiance permet de connaitre l'erreur que nous faisons en choisissant l'echantillon sur lequel nous travaillons et reponds à la question :\n",
    "Est-ce que notre echantillon est suffisament representatif de la population totale.\n",
    "\n",
    "1. Calculer la moyenne [x]\n",
    "2. Calculer l'ecart type [x]\n",
    "3. Determiner le niveau de confiance α - [x]\n",
    "4. Obtenir le Z-Score\n",
    "4. Calculer la marge d'erreur\n",
    "5. Etablir l'intervalle de confiance\n",
    "6. Interpréter les resultats\n",
    "7. Calculer le Z score\n",
    "\n",
    "\n",
    "#### 4.2.3. Mesures de tendance centrale\n",
    "\n",
    "Moyenne mediane et mode\n",
    "\n",
    "#### 4.2.4.  Mesures de dispersion\n",
    "1. Écart type : standard deviation\n",
    "\n",
    "La mesure de l'ecart type est l'ecart qu'il existe entre une valeur de l'echantillon et la moyenne de l'echantillon.\n",
    "Cette mesure permet d'observer la dispersion d'une distribution\n",
    "\n",
    "Il se calcul comme suit : \n",
    "$$\\sigma = \\sqrt{\\frac{\\sum_{1}^{n}(x_{n} - \\mu)^{2}}{n}}$$\n",
    "\n",
    " - avec $\\sigma$ l'ecrart type\n",
    " - $n$ nombre d'element dans l'echantillon\n",
    " - $\\mu$ moyenne arithmetique de l'echantillon\n",
    " - $x$ : l'element en cours\n",
    "\n",
    "\n",
    "2. Variance\n",
    "\n",
    "Ecart type au carré\n",
    "$\\sigma^2$\n",
    "\n",
    "\n",
    "3. Étendue\n",
    "\n",
    "#### 4.2.5. Analyse des distributions\n",
    "\n",
    "- Notion de quartile\n",
    "\n",
    "#### 4.2.6 Test d'hypothese\n",
    "\n",
    "* 1. Processus de test d'hypothèse\n",
    "\n",
    "Un test d'hypothese est \"simplement\" une methode qui permet de savoir si l'hypothese emise est bien dans la distribution de notre echantillon.\n",
    "Pour cela nous allons proceder comme suit :\n",
    "\n",
    "* 1.1\\. Emettre deux hypotheses antagonistes qui sont les opposées exactes notées $H_0$ et $H_1$.\n",
    "* 1.2\\. L'objectif est d'infirmer $H_0$ pour prouver $H_1$, \n",
    "\n",
    "Par ailleurs $H_0$ est appelé Hypothese nulle et $H_1$ hypothese alternative.\n",
    "\n",
    "\n",
    "2. Type de test\n",
    "\n",
    "Pour y parvenir nous utiliserons des tests permettatn de confirmer ou d'infirmer nos hypotheses.\n",
    "\n",
    " - Z-test (ou T-test): Pour compare deux moyenne ou deus proportions\n",
    " - Chi-Square test: Permet de prouver l'independance ou de comparer l'ecart type\n",
    " - ANOVA: Permet de comparer plus que deux moyennes ou deux proportions\n",
    "\n",
    "Concenrant le Z-Test, la methodologie à appliquer est la suivante :\n",
    "\n",
    " - Definir $H_0$​ et $H_1$​\n",
    " - Definir l'intervalle de confiance\n",
    " - Calculer le Z-Score\n",
    " - En deduire la P-Value\n",
    " - Comparer la P-Value à l'intervalle de confiance\n",
    " - Conclure !\n",
    "\n",
    "Ici, l'intervalle de confiance \\alpha est la probabilité en deça de laquelle on peut rejeter l'hypothese nulle $H_0$​\t\n",
    "Le contexte joue pour beaucoup dans l'analyse que l'on veut faire.  La comparaison avec l'intervalle de confiance depend donc du spectre de l'etude.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3. P-Value\n",
    "\n",
    "La P-Value représente simplement la probabilité que la moyenne (ou la proportion) de l'échantillon appartienne à la distribution du graphique.\n",
    "\n",
    "Si P-Value est inférieure à votre niveau de confiance α, vous pouvez rejeter H0\n",
    "\n",
    "\n",
    "4. Interpréter les résultats d'un test d'hypothèse\n",
    "\n",
    "5. A/B Test\n",
    "\n",
    "\n",
    "    1. Qu'est-ce qu'un test A/B ?\n",
    "\n",
    "    Les test A/B sont des moyens de comperer deux \"elemnts\"\n",
    "\n",
    "    2. Notions importantes à prendre en compte avant d'effectuer un test A/B\n",
    "\n",
    "\n",
    "\n",
    "    3. Comment créer un test A/B\n",
    "    \n",
    "    4. Les limites du test A/B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T17:56:08.275864Z",
     "start_time": "2024-11-11T17:56:08.184709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4.300000190734863, 51), (4.0, 43), (4.199999809265137, 43), (4.099999904632568, 42), (4.5, 41), (3.799999952316284, 38), (4.400000095367432, 36), (4.599999904632568, 35), (4.900000095367432, 31), (4.800000190734863, 31), (4.699999809265137, 28), (3.900000095367432, 24), (5.099999904632568, 23), (5.300000190734863, 19), (3.700000047683716, 18), (3.5999999046325684, 15), (5.199999809265137, 14), (5.0, 14), (3.5, 13), (0.0, 12), (5.400000095367432, 10), (5.800000190734863, 8), (1.2999999523162842, 7), (0.800000011920929, 7), (5.5, 6), (6.0, 6), (6.199999809265137, 5), (3.299999952316284, 5), (11.199999809265137, 5), (2.799999952316284, 5), (6.400000095367432, 5), (3.4000000953674316, 5), (2.700000047683716, 5), (11.399999618530272, 4), (9.800000190734863, 4), (5.699999809265137, 4), (1.7000000476837158, 4), (6.300000190734863, 4), (5.900000095367432, 4), (2.0, 3), (3.0999999046325684, 3), (11.600000381469728, 3), (6.099999904632568, 3), (1.2000000476837158, 3), (1.600000023841858, 3), (1.100000023841858, 3), (0.8999999761581421, 3), (1.399999976158142, 3), (10.0, 3), (0.699999988079071, 3), (5.599999904632568, 3), (4.483333110809326, 3), (15.699999809265137, 3), (7.900000095367432, 3), (9.199999809265137, 3), (7.300000190734863, 2), (11.0, 2), (6.599999904632568, 2), (5.14599609375, 2), (7.599999904632568, 2), (9.399999618530272, 2), (1.0, 2), (10.800000190734863, 2), (1.5, 2), (16.899999618530273, 2), (9.699999809265137, 2), (10.5, 2), (3.200000047683716, 2), (10.600000381469728, 2), (2.200000047683716, 2), (5.966015815734863, 2), (2.4000000953674316, 2), (5.928027153015137, 2), (11.5, 2), (0.1000000014901161, 2), (2.5999999046325684, 2), (13.199999809265137, 2), (14.399999618530272, 2), (13.300000190734863, 2), (16.5, 2), (12.699999809265137, 2), (14.800000190734863, 2), (3.0, 2), (15.600000381469728, 2), (6.800000190734863, 2), (7.330004692077637, 1), (7.273974418640137, 1), (6.762011528015137, 1), (6.547999382019043, 1), (6.733999729156494, 1), (6.775999546051025, 1), (6.576001167297363, 1), (6.561999797821045, 1), (6.571972846984863, 1), (7.227978706359863, 1), (7.175976753234863, 1), (6.808007717132568, 1), (6.720019340515137, 1), (6.710000514984131, 1), (6.844000339508057, 1), (6.6680006980896, 1), (7.02001953125, 1), (6.6419997215271, 1), (6.529980659484863, 1), (6.216015815734863, 1), (6.484033107757568, 1), (6.47802734375, 1), (5.803999900817871, 1), (5.801953315734863, 1), (5.794000148773193, 1), (5.790002346038818, 1), (5.767968654632568, 1), (5.744288921356201, 1), (5.735986232757568, 1), (5.7139892578125, 1), (5.703906059265137, 1), (5.696002006530762, 1), (5.690014839172363, 1), (5.670019626617432, 1), (5.662011623382568, 1), (5.651953220367432, 1), (5.637988090515137, 1), (5.807999610900879, 1), (5.840000152587891, 1), (5.911999702453613, 1), (6.351953029632568, 1), (6.471999645233154, 1), (6.4619140625, 1), (6.432031154632568, 1), (6.4119873046875, 1), (6.365997314453125, 1), (6.360000133514404, 1), (6.349999904632568, 1), (5.949999809265137, 1), (6.28000020980835, 1), (6.108007907867432, 1), (6.028002738952637, 1), (6.02001953125, 1), (5.982007026672363, 1), (5.959997653961182, 1), (7.338000297546387, 1), (9.0, 1), (7.352002143859863, 1), (11.003667831420898, 1), (14.5, 1), (14.3841552734375, 1), (14.300000190734863, 1), (14.151692390441896, 1), (14.093994140625, 1), (13.5, 1), (13.399999618530272, 1), (13.159765243530272, 1), (13.035998344421388, 1), (13.0, 1), (12.899999618530272, 1), (12.800000190734863, 1), (12.300000190734863, 1), (12.063989639282228, 1), (11.954004287719728, 1), (11.699999809265137, 1), (11.366000175476074, 1), (14.699999809265137, 1), (14.77197265625, 1), (15.141764640808104, 1), (17.08625030517578, 1), (20.700000762939453, 1), (18.899999618530273, 1), (18.67289161682129, 1), (18.399999618530273, 1), (17.399999618530273, 1), (17.299999237060547, 1), (17.100000381469727, 1), (17.0, 1), (15.218358993530272, 1), (16.799999237060547, 1), (16.700000762939453, 1), (16.505502700805664, 1), (16.399999618530273, 1), (16.0, 1), (15.396920204162598, 1), (15.300000190734863, 1), (11.300000190734863, 1), (10.954004287719728, 1), (7.3639984130859375, 1), (10.899999618530272, 1), (8.5, 1), (8.399999618530273, 1), (8.386133193969727, 1), (8.300000190734863, 1), (8.199999809265137, 1), (8.10400104522705, 1), (8.0, 1), (7.833984375, 1), (7.800000190734863, 1), (7.771996974945068, 1), (7.699999809265137, 1), (7.66400146484375, 1), (7.642001152038574, 1), (7.585001468658447, 1), (7.5, 1), (7.4739990234375, 1), (7.400000095367432, 1), (8.530004501342773, 1), (8.629980087280273, 1), (8.699999809265137, 1), (9.871973037719728, 1), (10.399999618530272, 1), (10.199999809265137, 1), (10.125391006469728, 1), (10.090039253234863, 1), (10.083996772766112, 1), (9.931982040405272, 1), (9.899999618530272, 1), (9.8366117477417, 1), (8.840006828308105, 1), (9.834972381591797, 1), (9.600000381469728, 1), (9.54400634765625, 1), (9.50633716583252, 1), (9.5, 1), (9.050000190734863, 1), (5.612011909484863, 1), (5.628003120422363, 1), (5.3699951171875, 1), (5.601953029632568, 1), (3.688000440597534, 1), (3.851524591445923, 1), (3.842996120452881, 1), (3.830664157867432, 1), (3.8179931640625, 1), (3.797999620437622, 1), (3.760000705718994, 1), (3.720019578933716, 1), (3.701953172683716, 1), (3.669921875, 1), (3.941992282867432, 1), (3.612011671066284, 1), (3.602001905441284, 1), (3.116666555404663, 1), (3.116650342941284, 1), (3.1100096702575684, 1), (3.1079955101013184, 1), (3.0721435546875, 1), (3.055999755859375, 1), (3.881332874298096, 1), (3.9574999809265137, 1), (2.9740021228790283, 1), (4.309999942779541, 1), (4.3681640625, 1), (4.366666793823242, 1), (4.357000827789307, 1), (4.340000152587891, 1), (4.339999675750732, 1), (4.335969924926758, 1), (4.324023246765137, 1), (4.316000461578369, 1), (4.21999979019165, 1), (3.984666347503662, 1), (4.197999477386475, 1), (4.179980278015137, 1), (4.169921875, 1), (4.139999866485596, 1), (4.133984565734863, 1), (4.1099982261657715, 1), (4.058007717132568, 1), (4.039333343505859, 1), (2.987988233566284, 1), (2.9600000381469727, 1), (4.412499904632568, 1), (1.3240000009536743, 1), (2.0799996852874756, 1), (2.049999952316284, 1), (1.9019997119903564, 1), (1.862499952316284, 1), (1.8285714387893677, 1), (1.7987964153289795, 1), (1.690000057220459, 1), (1.628000020980835, 1), (1.2239990234375, 1), (2.273998975753784, 1), (1.2139892578125, 1), (1.0080000162124634, 1), (0.959999978542328, 1), (0.9580000042915344, 1), (0.8474576473236084, 1), (0.830004870891571, 1), (0.4031413197517395, 1), (0.4000000059604645, 1), (2.1560018062591553, 1), (2.299999952316284, 1), (2.9000000953674316, 1), (2.518017530441284, 1), (2.868668556213379, 1), (2.867993116378784, 1), (2.7800049781799316, 1), (2.7339844703674316, 1), (2.732000827789306, 1), (2.612499952316284, 1), (2.5900025367736816, 1), (2.5480010509490967, 1), (2.5, 1), (2.302001953125, 1), (2.4600000381469727, 1), (2.455004930496216, 1), (2.4260010719299316, 1), (2.410001516342163, 1), (2.3979995250701904, 1), (2.3899903297424316, 1), (2.354663133621216, 1), (2.329333543777466, 1), (4.3979997634887695, 1), (4.420019626617432, 1), (5.594140529632568, 1), (5.241991996765137, 1), (5.340000152587891, 1), (5.316015720367432, 1), (5.311999320983887, 1), (5.303999900817871, 1), (5.298004150390625, 1), (5.289999485015869, 1), (5.274023532867432, 1), (5.244042873382568, 1), (5.231982231140137, 1), (5.353999137878418, 1), (5.2166666984558105, 1), (5.214062690734863, 1), (5.195996284484863, 1), (5.193945407867432, 1), (5.191998481750488, 1), (5.173998832702637, 1), (5.169999599456787, 1), (5.144140720367432, 1), (5.352002143859863, 1), (5.362011909484863, 1), (5.098046779632568, 1), (5.473828315734863, 1), (5.578517913818359, 1), (5.575976371765137, 1), (5.571999549865723, 1), (5.547999382019043, 1), (5.540002346038818, 1), (5.534008979797363, 1), (5.52001953125, 1), (5.508001804351807, 1), (5.445996284484863, 1), (5.368066310882568, 1), (5.426025390625, 1), (5.424023628234863, 1), (5.418164253234863, 1), (5.4160003662109375, 1), (5.41400146484375, 1), (5.411999702453613, 1), (5.39404296875, 1), (5.3800048828125, 1), (5.114001274108887, 1), (5.096093654632568, 1), (4.4320068359375, 1), (4.6220703125, 1), (4.740000247955322, 1), (4.729992866516113, 1), (4.698000431060791, 1), (4.696000576019287, 1), (4.683333396911621, 1), (4.681933403015137, 1), (4.64404296875, 1), (4.635998725891113, 1), (4.607995510101318, 1), (4.763183116912842, 1), (4.598046779632568, 1), (4.550000190734863, 1), (4.514062404632568, 1), (4.509997367858887, 1), (4.502148628234863, 1), (4.476972579956055, 1), (4.449999809265137, 1), (4.447999954223633, 1), (4.758008003234863, 1), (4.766000270843506, 1), (5.087988376617432, 1), (4.925996780395508, 1), (5.079999923706055, 1), (5.054003715515137, 1), (5.051953315734863, 1), (5.043993949890137, 1), (5.035998344421387, 1), (5.022003173828125, 1), (4.97802734375, 1), (4.946002006530762, 1), (4.920019626617432, 1), (4.771996974945068, 1), (4.901998996734619, 1), (4.8866658210754395, 1), (4.886000156402588, 1), (4.883333206176758, 1), (4.871972560882568, 1), (4.835986137390137, 1), (4.801953315734863, 1), (4.781982421875, 1), (25.643980026245117, 1)]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Statistics' object has no attribute 'floatConvert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 131\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m#st = Statistics(sample, \"value\", debug=True)\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m#myStrava = Statistics(sample, \"Vitesse max.\", debug=False)\u001b[39;00m\n\u001b[1;32m    127\u001b[0m myStrava \u001b[38;5;241m=\u001b[39m Statistics(sample, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVitesse max.\u001b[39m\u001b[38;5;124m\"\u001b[39m, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 131\u001b[0m val  \u001b[38;5;241m=\u001b[39m \u001b[43mmyStrava\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetDistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(val, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpace\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreq\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpace\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m plot \u001b[38;5;241m=\u001b[39m sns\u001b[38;5;241m.\u001b[39mdisplot(data\u001b[38;5;241m=\u001b[39mdf, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpace\u001b[39m\u001b[38;5;124m\"\u001b[39m, legend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 89\u001b[0m, in \u001b[0;36mStatistics.getDistribution\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m occurences \u001b[38;5;241m=\u001b[39m [(val, key) \u001b[38;5;28;01mfor\u001b[39;00m val, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset]\u001b[38;5;241m.\u001b[39msort_values()\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mitems() ]\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(occurences)\n\u001b[0;32m---> 89\u001b[0m dataset \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloatConvert\u001b[49m(val),key) \u001b[38;5;28;01mfor\u001b[39;00m val, key \u001b[38;5;129;01min\u001b[39;00m occurences]\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistribution\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Statistics' object has no attribute 'floatConvert'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sample=pd.read_csv('../Datas/Strava/activities.csv')\n",
    "\n",
    "#sample=pd.read_csv('../Datas/Tests/df.csv')\n",
    "\n",
    "#display(sample.head(10))\n",
    "\n",
    "# on utilise ici un dataset des mes courses sur Strava\n",
    "# notre objectif va etre d'estimer la performance d'une sortie de ce coureur en fonction de son historique de course.\n",
    "# pour cela nous allons observer uniquement la distance parcourue. \n",
    "\n",
    "# On pourra (quand on sera pus fort), regarder la vitesse moyenne sur chacune des courses pour connaitre sa performance selon les distances \n",
    "\n",
    "class centralTendency(object):\n",
    "     \n",
    "    def __init__(self,sample, subset, debug=False): \n",
    "        super(centralTendency, self).__init__(sample, subset, debug=False)\n",
    "\n",
    "    def meanPython(self):\n",
    "        if self.debug:\n",
    "            print(\"Calcul de la moyenne avec NumPy\")\n",
    "            print(np.mean(self.sample[self.subset]))\n",
    "        return np.mean(self.sample[self.subset])\n",
    "    \n",
    "    def mean(self):\n",
    "        if self.debug:\n",
    "            print(\"Calcul de la moyenne\")\n",
    "            print(np.mean(self.sample[self.subset]))        \n",
    "        return (self.sample[self.subset].sum()) / len(self.sample)\n",
    "\n",
    "    def medianPython(self):\n",
    "        if self.debug:\n",
    "            print(\"Calcul de la médiane avec numPy\")\n",
    "            print(np.median(self.sample[self.subset]))\n",
    "            \n",
    "        return np.median(self.sample[self.subset])\n",
    "    \n",
    "    def median(self):\n",
    "\n",
    "        n = self.numberSample()\n",
    "        orderedSample = self.sample[self.subset].sort_values()\n",
    "\n",
    "        if n % 2 == 0:\n",
    "            median = (orderedSample.iloc[n // 2] + orderedSample.iloc[n // 2 - 1]) / 2        \n",
    "        else:\n",
    "            median =  orderedSample.iloc[len(orderedSample) // 2]\n",
    "    \n",
    "        if self.debug:\n",
    "            print(\"Calcul de la médiane\")\n",
    "            print(median)\n",
    "\n",
    "        return median\n",
    "\n",
    "\n",
    "    def mode(self):\n",
    "        occurences = Statistics.getDistribution(self)[0]\n",
    "\n",
    "        if self.debug:\n",
    "            print(\"Calcul du mode, la valeur {} apparait {} fois\".format(occurences[0], occurences[1]))\n",
    "\n",
    "        return occurences[0]\n",
    "        \n",
    "\n",
    "\n",
    "class Statistics(centralTendency): # cette classe herite de la classe centralTendency\n",
    "\n",
    "\n",
    "    def __init__(self, sample, subset, debug=False):\n",
    "        self.sample = sample.dropna(subset=[subset])\n",
    "        self.subset = subset\n",
    "        self.debug = debug\n",
    "\n",
    "    def floatConverter(self,val):    \n",
    "        if type(val) == float:\n",
    "            return val\n",
    "        else:\n",
    "            try:\n",
    "                return float(val.replace(\",\", \".\"))\n",
    "            except:\n",
    "                return \n",
    "\n",
    "\n",
    "    def getDistribution(self):\n",
    "        occurences = [(val, key) for val, key in self.sample[self.subset].sort_values().value_counts().items() ]\n",
    "        print(occurences)\n",
    "        dataset = [(self.floatConvert(val),key) for val, key in occurences]\n",
    "       \n",
    "        if self.debug:\n",
    "            print(\"Distribution\")\n",
    "            print(dataset)\n",
    "\n",
    "        return dataset #({key: val for val, key in occurences})  # Convertir en JSON\n",
    "\n",
    "\n",
    "\n",
    "    def numberSample(self):\n",
    "        return len(self.sample)\n",
    "\n",
    "    def stdPython(self):\n",
    "        if self.debug:\n",
    "            print(\"Calcul de l'écart type avec NumPy\")\n",
    "            print(np.std(self.sample[self.subset]))\n",
    "        return np.std(self.sample[self.subset])\n",
    "    \n",
    "    def std(self):\n",
    "        mean = self.mean()\n",
    "        n = self.numberSample()\n",
    "        squareDiff = [pow((xi - mean),2) for xi in self.sample[self.subset]] # on calcul le carré de l'ecart à la moyenne de chaque valeur\n",
    "        squareMean = [val/n for val in squareDiff] # on cherche la moyenne des carés\n",
    "        sumSquareMean =  sum(squareMean)\n",
    "        std = pow(sumSquareMean,0.5) # on prend la racine carrée de cette somme\n",
    "\n",
    "        if self.debug:\n",
    "            print(\"Calcul de l'écart type\")\n",
    "            print(std)\n",
    "\n",
    "        return std\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#st = Statistics(sample, \"value\", debug=True)\n",
    "#myStrava = Statistics(sample, \"Vitesse max.\", debug=False)\n",
    "myStrava = Statistics(sample, \"Vitesse max.\", debug=False)\n",
    "\n",
    "\n",
    "\n",
    "val  = myStrava.getDistribution()\n",
    "df = pd.DataFrame(val, columns=['pace', 'freq']).sort_values(by='pace', ascending=True)\n",
    "\n",
    "\n",
    "plot = sns.displot(data=df, x=\"pace\", legend='df')\n",
    "plot.set_titles(\"Distribution of pace\").set_xlabels(\"Pace in min/km\").set_ylabels(\"Frequency\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "centralTendency.mean() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmyStrava\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVitesse max.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(myStrava\u001b[38;5;241m.\u001b[39mmode())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(myStrava\u001b[38;5;241m.\u001b[39mmedian())\n",
      "\u001b[0;31mTypeError\u001b[0m: centralTendency.mean() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "print(myStrava.mean())\n",
    "\n",
    "print(myStrava.mode())\n",
    "print(myStrava.median())\n",
    "print(myStrava.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#____________________________________________________________________________________\n",
    "# 1 Calculer la moyenne\n",
    "print(\"______________________________________________________\")\n",
    "print(\"1 . Calcul de la moyenne de la distance en metre______________\")\n",
    "\n",
    "display(sample['Distance'])\n",
    "\n",
    "\n",
    "mean = np.mean(sample[\"Distance\"].to)\n",
    "n = len(sample)\n",
    "print(\"Moyenne : \", mean)\n",
    "print('En moyenne cet utilisateur court sur une distance de ', round(mean)/1000, 'kilomètres')\n",
    "print(\"______________________________________________________\")\n",
    "#____________________________________________________________________________________\n",
    "# 2 Calculer l'ecart type\n",
    "print(\"2. Calcul de l'ecart type________________________\")\n",
    " \n",
    "# on calcul le carré des ecarts à la moyenne\n",
    "squareDeviation  = [pow((val),2) for val in sample[\"distance\"]]\n",
    "# on fait la somme de ces ecarts\n",
    "sumDeviation = sum(squareDeviation)\n",
    "sumDeviationAvg = sumDeviation / n\n",
    "standardDeviation = pow(sumDeviationAvg,0.5)\n",
    "print(  \"Ecart type calculé : \", standardDeviation)\n",
    "\n",
    "std = np.std(sample[\"distance\"])\n",
    "print(\"Ecart type pythonifié : \", std)\n",
    "\n",
    "ecartSTD = abs(standardDeviation - std)\n",
    "print(\"Ecart entre Ò calculé et Ò pythonifié : \", ecartSTD)\n",
    "\n",
    "# on gardera le resuylat python pour la suite des calculs soit std\n",
    "\n",
    "#____________________________________________________________________________________\n",
    "# 3 Determiner le niveau de confiance α\n",
    "print(\"______________________________________________________\")\n",
    "print(\"3. Determiner le niveau de confiance α (entre 0 et 1) de cette information, par defaut 95%\")\n",
    "confidence_level = 0.95\n",
    "print(\"Niveau de confiance α : \", confidence_level)\n",
    "\n",
    "#____________________________________________________________________________________\n",
    "# 4 Obtenir le Z-Score\n",
    "print(\"______________________________________________________\")\n",
    "print(\"calcul du Z score_____________________________________\")\n",
    "\n",
    "def zscoreCalc(val):\n",
    "    return (val - mean) / std\n",
    "\n",
    "print(\"En cours de dev : \",zscoreCalc(confidence_level))\n",
    "\n",
    "zScore=[zscoreCalc(val) for val in sample[\"distance\"]]\n",
    "\n",
    "#Il faut trouver 1,96 ici pour un niveau de confiance à 95%\n",
    "\n",
    "zScore = 1.96\n",
    "\n",
    "\n",
    "print(\"_________________________________________\")\n",
    "print(\" Calculer la marge d'erreur______________\")\n",
    "errorMargin = zScore * (std / pow(n,0,5))\n",
    "print(\"Marge d'erreur : \", errorMargin)\n",
    "print(\"_________________________________________\")\n",
    "\n",
    "#ci  = meanSample +- (z * (stdSample / sqrt(n)))\n",
    "\n",
    "sns.displot(sample[\"distance\"], color='c', edgecolor='black')\n",
    "#plt.hist(sample[\"distance\"], bins=100, color='c', edgecolor='black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- Exemple de calcul de l'intervalle de confiance\n",
    "  - Soit un echantillon S de taille n = 100\n",
    "    -  /{x_1, x_2, ..., x_n}/\n",
    "    - La moyenne de l'echanillon est de $\\bar{m}$ = 18 \n",
    "    - Ecart type = 3\n",
    "    - Intervalle de confiance = 95%\n",
    "    - Calcul de l'interval de confiance\n",
    "    - $IC = \\bar{x} \\pm Z \\cdot \\frac{\\sigma}{\\sqrt{n}}$\n",
    "    - $IC = 100 \\pm 1.96 \\cdot \\frac{10}{\\sqrt{100}}$\n",
    "    - $IC = 100 \\pm 1.96 \\cdot 1$\n",
    "    - $IC = 100 \\pm 1.96$\n",
    "    - $IC = [98.04, 101.96]$\n",
    "    - L'intervalle de confiance est donc [98.04, 101.96]\n",
    "    - Cela signifie que la moyenne de la population totale est comprise entre 98.04 et 101.96 avec un niveau de confiance de 95%\n",
    "    - Si on avait pris un niveau de confiance de 99%, on aurait eu un intervalle de confiance plus large\n",
    "    -  $IC = 100 \\pm 2.58 \\cdot 1$\n",
    "    -  $IC = 100 \\pm 2.58$\n",
    "    -  $IC = [97.42, 102.58]$\n",
    "    - L'intervalle de confiance est donc [97.42, 102.58]\n",
    "    -  Cela signifie que la moyenne de la population totale est comprise entre 97.42 et 102.58 avec un niveau de confiance de 99%\n",
    "    - Plus le niveau de confiance est élevé, plus l'intervalle de confiance est large\n",
    "    -  Plus l'intervalle de confiance est large, plus on est sûr que la moyenne de la population totale est comprise\n",
    "    -  dans cet intervalle\n",
    "    - Plus l'intervalle de confiance est large, moins on est sûr de la précision de notre estimation\n",
    "    -  Plus l'intervalle de confiance est large, plus on a besoin d'un échantillon important pour le calculer\n",
    "                                                                                                                                                            \n",
    "    \n",
    "#### 4.2.3. Mesures de tendance centrale\n",
    "\n",
    "\n",
    "\n",
    "#### 4.2.4.  Mesures de dispersion\n",
    "1. Variance\n",
    "\n",
    "  \n",
    "\n",
    "2. Ecart type : standard deviation\n",
    "\n",
    "3. Etendue\n",
    "\n",
    "#### 4.2.5. Analyse des distributions\n",
    "\n",
    "- Notion de quartil\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Logique et Raisonnement\n",
    "- Logique propositionnelle\n",
    "- Raisonnement déductif et inductif\n",
    "- Preuves mathématiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ressources Supplémentaires\n",
    "- Livres recommandés\n",
    "- Sites web et vidéos éducatives\n",
    "\n",
    "    * https://machinelearningmastery.com/statistical-hypothesis-tests-in-python-cheat-sheet/\n",
    "    \n",
    "\n",
    "- Applications et outils en ligne\n",
    "- Sources de données :\n",
    "\n",
    "- http://data.worldbank.org/ # World Bank\n",
    "- https://github.com/fivethirtyeight/data # FiveThirtyEight\n",
    "- https://github.com/BuzzFeedNews # Buzzfeed\n",
    "- https://opendata.socrata.com/ # Open data \n",
    "- https://registry.opendata.aws/ # Amazon Web Services\n",
    "- https://cloud.google.com/bigquery/public-data/ # Google Big Query\n",
    "- https://en.wikipedia.org/wiki/Wikipedia:Database_download # Wikipedia\n",
    "- https://www.kaggle.com/datasets # Kaggle datasets \n",
    "- https://archive.ics.uci.edu/datasets # Machine learning\n",
    "- https://www.dataquest.io/blog/free-datasets-for-projects/ # Free datasets for projects \n",
    "- https://data.nasdaq.com/ # Finance\n",
    "- https://data.world/ # Datasets from the community \n",
    "- https://www.reddit.com/r/datasets/top/?sort=top&t=all # Reddit\n",
    "- http://academictorrents.com/browse.php # Torrents\n",
    "- https://dev.twitter.com/streaming/overview # Twitter\n",
    "- https://www.quandl.com/ # Finance \n",
    "- https://www.quantopian.com/ # Finance \n",
    "- https://www.wunderground.com/weather/api/ # Weather data\n",
    "\n",
    "    ** Institutionnels **\n",
    "\n",
    "- https://www.data.gouv.fr/fr/ # France\n",
    "- https://www.data.gov/ # USA\n",
    "- https://www.data.gov.uk/ # UK\n",
    "- https://www.data.qld.gov.au/ # Queensland\n",
    "- https://www.data.vic.gov.au/ # Victoria\n",
    "- https://www.data.sa.gov.au/ # South Australia\n",
    "- https://www.data.nsw.gov.au/ # New South Wales\n",
    "- https://www.data.wa.gov.au/ # Western Australia\n",
    "- https://www.data.act.gov.au/ # Australian Capital Territory\n",
    "- https://www.data.nt.gov.au/ # Northern Territory\n",
    "- https://www.data.tas.gov.au/ # Tasmania\n",
    "- https://www.data.govt.nz/ # New Zealand\n",
    "- https://www.data.gov.sg/ # Singapore\n",
    "- https://www.data.gov.hk/ # Hong Kong    \n",
    "- https://www.data.gov.tw/ # Taiwan\n",
    "- https://www.data.go.kr/ # South Korea\n",
    "- https://www.data.go.jp/ # Japan\n",
    "- https://www.data.gov.my/ # Malaysia\n",
    "- https://www.data.gov.ph/ # Philippines\n",
    "- https://www.data.gov.vn/ # Vietnam\n",
    "- https://www.data.gov.in/ # India\n",
    "- https://www.data.gov.pk/ # Pakistan\n",
    "- https://www.data.gov.bd/ # Bangladesh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
